{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from gc import collect\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.sparse import hstack\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename='../out/submit.csv',\n",
    "    path_to_sample='../data/sample_submission.csv'):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_loglength(df, X, scaler, fit):   \n",
    "    loglength = df['log_length']\n",
    "    if fit:\n",
    "        loglength = scaler.fit_transform(loglength.values.reshape(-1, 1)) # \n",
    "    else:\n",
    "        loglength = scaler.transform(loglength.values.reshape(-1, 1))\n",
    "    return scaler, hstack((X, loglength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_day(df, X, scaler, fit):   \n",
    "    day = df['delta_time'].astype(np.float)\n",
    "    if fit:\n",
    "        day = scaler.fit_transform(day.values.reshape(-1, 1)) # \n",
    "    else:\n",
    "        day = scaler.transform(day.values.reshape(-1, 1))\n",
    "    return scaler, hstack((X, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(lang):\n",
    "    top_langs = ['en', 'pt', 'es', 'fr', 'it', 'ru', 'tr', 'ja', 'de', 'id']\n",
    "    return lang if lang in top_langs else 'other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hour(df, X_sparse):\n",
    "    X = X_sparse\n",
    "    hour = df['time'].apply(lambda ts: ts.hour)\n",
    "    for i in range(0,24):\n",
    "        X = hstack((X, (hour == i).astype('int').values.reshape(-1, 1)))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 424 ms, sys: 13.6 ms, total: 437 ms\n",
      "Wall time: 633 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_pickle('../data/train.pickle', compression='xz')\n",
    "train.drop(train[train.length == 0].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62253, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lang'] = train['lang'].apply(lambda x: get_lang(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train.date)\n",
    "train['time'] = pd.to_datetime(train.time)#.apply(lambda x: x.time()\n",
    "train['time'] = train.time.apply(lambda x: x.time())\n",
    "train['year_month'] = train['date'].apply(lambda x: 100 * x.year + x.month)\n",
    "train['year'] = train['date'].apply(lambda x: x.year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.051711004770855, 1.9252352577043828, 11.25157, (62253, 15))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sort_values(by='year_month', inplace=True)\n",
    "train.drop(train[train.length == 0].index, axis=0, inplace=True)\n",
    "\n",
    "train['target'].mean(), train['target'].std(),  train['target'].max(), train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target_expm'] = train['target'].apply(lambda x: np.expm1(x))\n",
    "train['log_length'] = train['length'].apply(lambda x: np.log10(x+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[\n",
    "    (train.target > train.target.quantile(0.1)) &\n",
    "    (train.target < train.target.quantile(0.98)) &\n",
    "    (train.length < train.length.quantile(.99)) &\n",
    "    (train.log_length > train.log_length.quantile(.01))\n",
    "]\n",
    "train = train[train.year > 2012]\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindate = train.date.min()\n",
    "train['delta_date'] = (train['date'] - mindate)\n",
    "train['delta_date'] = train['delta_date'].apply(lambda x: x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45154     2\n",
       "25360    14\n",
       "50640    21\n",
       "58055     6\n",
       "38292     8\n",
       "Name: delta_date, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['delta_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corps = pd.read_csv('../data/train_corps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer = make_scorer(mean_absolute_error)\n",
    "y = train.target.values\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 29s, sys: 5.12 s, total: 4min 34s\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, max_features=80000, ngram_range=(1,2)) #, binary=True)#, c\n",
    "X_corp = tfidf.fit_transform(list(train_corps['content'].iloc[train.index]))\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.1690, std = 0.0242\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X_corp, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.1676, std = 0.0245\n"
     ]
    }
   ],
   "source": [
    "\n",
    "langvec = CountVectorizer(binary=True, )\n",
    "lang_train = langvec.fit_transform(train.lang)\n",
    "X_train = hstack((X_corp, lang_train))\n",
    "cv = cross_val_score(Ridge(), X_train, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.0630, std = 0.0497\n"
     ]
    }
   ],
   "source": [
    "authorvec = CountVectorizer(binary=True)\n",
    "author_train = authorvec.fit_transform(train.author)\n",
    "X_train = hstack((X_train, author_train))\n",
    "cv = cross_val_score(Ridge(), X_train, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.0350, std = 0.0494\n"
     ]
    }
   ],
   "source": [
    "titlevec = TfidfVectorizer(ngram_range=(1,3)) #, min_df=2\n",
    "title_train = titlevec.fit_transform(train.tittle)\n",
    "X_train = hstack((X_train,  title_train))\n",
    "cv = cross_val_score(Ridge(), X_train, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.0297, std = 0.0500\n"
     ]
    }
   ],
   "source": [
    "train['corp_tags'] = train.tags.apply(lambda x: ' '.join(json.loads(x)))\n",
    "tagvec = TfidfVectorizer(ngram_range=(1,3)) #, binary=True, min_df=2\n",
    "tag_train = tagvec.fit_transform(train.corp_tags)\n",
    "X_train = hstack((X_train, tag_train))\n",
    "cv = cross_val_score(Ridge(), X_train, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.0257, std = 0.0482\n"
     ]
    }
   ],
   "source": [
    "llscaler, X_train = add_loglength(train, X_train, MinMaxScaler(), True)\n",
    "cv = cross_val_score(Ridge(), X_train, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 1.0252, std = 0.0478\n"
     ]
    }
   ],
   "source": [
    "X_train = add_hour(df=train, X_sparse=X_train)\n",
    "cv = cross_val_score(Ridge(), X_train, y, cv=4, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52043, 962128)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('../data/test.pickle', compression='xz')\n",
    "test_corps = pd.read_csv('../data/test_corps.csv')\n",
    "corps = list(test_corps['content'])\n",
    "corps = [str(line) for line in corps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['lang'] = test['lang'].apply(lambda x: get_lang(x))\n",
    "test['date'] = pd.to_datetime(test.date)\n",
    "test['time'] = pd.to_datetime(test.time)#.apply(lambda x: x.time()\n",
    "test['time'] = test.time.apply(lambda x: x.time())\n",
    "test['year_month'] = test['date'].apply(lambda x: 100 * x.year + x.month)\n",
    "test['log_length'] = test['length'].apply(lambda x: np.log10(x+1))\n",
    "X_corp_test = tfidf.transform(corps)\n",
    "test['corp_tags'] = test.tags.apply(lambda x: ' '.join(json.loads(x)))\n",
    "lang_test = langvec.transform(test.lang)\n",
    "author_test = authorvec.transform(test.author)\n",
    "title_test = titlevec.transform(test.tittle)\n",
    "tag_test = tagvec.transform(test.corp_tags)\n",
    "X_test = hstack((X_corp_test, lang_test, author_test, title_test, tag_test))\n",
    "scaler, X_test = add_loglength(test, X_test, llscaler, False)\n",
    "X_test = add_hour(df=test, X_sparse=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34645, 962128)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation: mean = 0.9960, std = 0.0489\n"
     ]
    }
   ],
   "source": [
    "cv = cross_val_score(Ridge(), X_train, y, cv=8, n_jobs=-1, scoring=scorer)\n",
    "print(f'Crossvalidation: mean = {cv.mean():.4f}, std = {cv.std():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y)\n",
    "pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4225321235960666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred += (4.33328 - pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 843k/843k [00:10<00:00, 84.8kB/s]\n",
      "Successfully submitted to How good is your Medium article?"
     ]
    }
   ],
   "source": [
    "write_submission_file(prediction=pred, filename='../out/tags_tfidf_ridge.csv')\n",
    "message = '\"tags, titles, authors, months and dirty hack\"' #input('Информация о модели\\n')\n",
    "!kaggle competitions submit -c how-good-is-your-medium-article -f ../out/tags_tfidf_ridge.csv -m {message}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
